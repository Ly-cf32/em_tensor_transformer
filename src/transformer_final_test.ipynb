{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca7d20b1-1deb-470e-bf47-4485b928c345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import argparse\n",
    "from numpy import arange, random\n",
    "from torch import save, load, no_grad, LongTensor\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2d02bca-8763-4826-9061-c37b87f2a364",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indata_loader(num_file):\n",
    "    data_array = []\n",
    "    for i in range(num_file):\n",
    "        file_name = '/home/mist/mix/mix_np_out/m_' + str(i+1) + '_a_xa.temt' # \n",
    "        array = np.loadtxt(file_name, skiprows=1, usecols = 1) + 3 # +3免去<bos>,<eos>,<pad>的影响\n",
    "        data_array.append(array)\n",
    "    return data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5e82681-714d-4d2f-812f-6f75f5b6d75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outdata_loader(num_file):\n",
    "    data_array = []\n",
    "    for i in range(num_file):\n",
    "        file_name = '/home/mist/pc/wig_fin/pc_fin_' + str(i+1) + '.npy' #\n",
    "        array = np.load(file_name) + 3 # +3免去<bos>,<eos>,<pad>的影响\n",
    "        for i in range(num_file):\n",
    "            data_array.append(array)\n",
    "    return data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b74a21ea-1e0a-479c-8b1f-840aeedcab17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# abundanceloader\n",
    "import numpy as np\n",
    "from torch import LongTensor\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# sequence_length = 1999-1 # ighm\n",
    "class AbundanceLoader(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        if len(x) != len(y):\n",
    "            raise ValueError(\"len(x) != len(y)\")\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return LongTensor(self.x[index]), LongTensor([0] + self.y[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7fbeeb35-07dd-4d25-854f-5af133f88752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "import torch\n",
    "from torch import nn\n",
    "import math\n",
    "\n",
    "# positional encoding\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, dropout=0.1, max_len=1998):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1) #\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "# transformer model\n",
    "class TransformerModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, intoken, outtoken, hidden, nlayers=3, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        nhead = hidden // 64\n",
    "\n",
    "        self.encoder = nn.Embedding(intoken, hidden) # nn.Embedding:词典大小，词向量维度\n",
    "        self.pos_encoder = PositionalEncoding(hidden, dropout)\n",
    "\n",
    "        self.decoder = nn.Embedding(outtoken, hidden)\n",
    "        self.pos_decoder = PositionalEncoding(hidden, dropout)\n",
    "\n",
    "        self.inscale = math.sqrt(intoken)\n",
    "        self.outscale = math.sqrt(outtoken)\n",
    "\n",
    "        self.transformer = nn.Transformer(d_model=hidden, nhead=nhead, num_encoder_layers=nlayers,\n",
    "                                          num_decoder_layers=nlayers, dim_feedforward=hidden, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(hidden, outtoken)\n",
    "\n",
    "        self.src_mask = None\n",
    "        self.trg_mask = None\n",
    "        self.memory_mask = None\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = torch.triu(torch.ones(sz, sz), 1)\n",
    "        mask = mask.masked_fill(mask == 1, float('-inf'))\n",
    "        return mask\n",
    "\n",
    "    def make_len_mask(self, inp):\n",
    "        return (inp == 0).transpose(0, 1)\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        if self.trg_mask is None or self.trg_mask.size(0) != len(trg):\n",
    "            self.trg_mask = self.generate_square_subsequent_mask(len(trg)).to(trg.device)\n",
    "\n",
    "        src_pad_mask = self.make_len_mask(src)\n",
    "        trg_pad_mask = self.make_len_mask(trg)\n",
    "\n",
    "        src = self.encoder(src)\n",
    "        src = self.pos_encoder(src)\n",
    "\n",
    "        trg = self.decoder(trg)\n",
    "        trg = self.pos_decoder(trg)\n",
    "        output = self.transformer(src, trg, tgt_mask=self.trg_mask)\n",
    "        # output = self.transformer(src, trg, src_mask=self.src_mask, tgt_mask=self.trg_mask,\n",
    "        #                           memory_mask=self.memory_mask,\n",
    "        #                           src_key_padding_mask=src_pad_mask, tgt_key_padding_mask=trg_pad_mask,\n",
    "        #                           memory_key_padding_mask=src_pad_mask)\n",
    "        output = self.fc_out(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d389b548-1455-4a3f-b263-ce7229c33246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 3, 3,  ..., 3, 3, 3])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "734f7e91-92ce-4124-826b-af7e96913784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_seq, model, max_length=1998):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Do not calculate gradients\n",
    "        # Convert input to tensor\n",
    "        input_tensor = torch.tensor(input_seq).unsqueeze(1).to(device)  # Reshape and move to device\n",
    "        # Create initial decoder input (start with the start-of-sequence token)\n",
    "        decoder_input = torch.tensor([1]).unsqueeze(1).to(device)  # Here we assume 1 is the <sos> token\n",
    "        output = []\n",
    "        for _ in range(max_length):\n",
    "            output_tensor = model(input_tensor, decoder_input)\n",
    "            # Choose the word with the highest probability\n",
    "            prediction = output_tensor.argmax(dim=2)[-1, :].item()\n",
    "            if prediction == 2:  # Stop if end-of-sequence token is predicted, we assume 2 is the <eos> token\n",
    "                break\n",
    "            output.append(prediction)\n",
    "            # Add prediction to decoder input\n",
    "            decoder_input = torch.cat((decoder_input, torch.tensor([[prediction]]).to(device)), dim=0)\n",
    "    return output  # This is a list of predicted indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d18d15a6-a632-4e75-a239-ea9d8f296de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_262/2261571953.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_tensor = torch.tensor(input_seq).unsqueeze(1).to(device)  # Reshape and move to device\n"
     ]
    }
   ],
   "source": [
    "a=predict(test_set[0][0],model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73956379-8437-41d5-ac08-096bc1fbe7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练过程\n",
    "def train(model, criterion, optimizer, loader):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(loader):\n",
    "        src, tgt = batch\n",
    "        src, tgt = src.transpose(1, 0).cuda(), tgt.transpose(1, 0).cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, tgt[:-1, :])\n",
    "        n = output.shape[-1]\n",
    "        loss = criterion(output.reshape(-1, n), tgt[1:, :].reshape(-1))\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(loader)\n",
    "\n",
    "\n",
    "# 验证\n",
    "def validation(model, criterion, loader):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with no_grad():\n",
    "        for i, batch in enumerate(loader):\n",
    "            src, tgt = batch\n",
    "            src, tgt = src.transpose(1, 0).cuda(), tgt.transpose(1, 0).cuda()\n",
    "            output = model(src, tgt[:-1, :])\n",
    "            n = output.shape[-1]\n",
    "            loss = criterion(output.reshape(-1, n), tgt[1:, :].reshape(-1))\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(loader)\n",
    "\n",
    "\n",
    "# # 测试\n",
    "def test(model, test_set, max_len=1998):\n",
    "    model = model.cuda()\n",
    "    model.eval()\n",
    "    with no_grad():\n",
    "        for i in range(len(test_set)):\n",
    "            cpu_src = test_set[i][0].numpy()\n",
    "            src = LongTensor(cpu_src).unsqueeze(1).cuda()\n",
    "            tgt = test_set[i][1].numpy()\n",
    "            np.savetxt('/home/mist/test/test_src_'+str(i)+'.txt',cpu_src, delimiter='\\n') #\n",
    "            np.savetxt('/home/mist/test/test_tgt_'+str(i)+'.txt',tgt, delimiter='\\n') #\n",
    "            pred = [0]\n",
    "            for j in range(max_len):\n",
    "                inp = LongTensor(pred).unsqueeze(1).cuda()\n",
    "                output = model(src,inp)\n",
    "                # predict = model.predictor(out[:, -1])\n",
    "                out_num = output.argmax(2)[-1].item()\n",
    "                pred.append(out_num)\n",
    "            np.savetxt('/home/mist/test/pred_'+str(i)+'.txt',pred,delimiter='\\n') #\n",
    "\n",
    "# def test(model, loader, max_len =1998):\n",
    "#     model.eval()\n",
    "#     with no_grad():\n",
    "#         for i, batch in enumerate(loader):\n",
    "#             src, tgt = batch\n",
    "#             print(\"input: \", src)\n",
    "#             print(\"target: \", tgt)\n",
    "#             np.savetxt('/home/mist/test/test_src_'+str(i)+'.txt',src.numpy(), newline='\\n') #\n",
    "#             np.savetxt('/home/mist/test/test_tgt_'+str(i)+'.txt',tgt.numpy(), newline='\\n') #\n",
    "#             src, tgt = src.transpose(1, 0).cuda(), tgt.transpose(1, 0).cuda()\n",
    "#             pred = [0]\n",
    "#             for j in range(max_len):\n",
    "#                 inp = LongTensor(pred).unsqueeze(1).cuda()\n",
    "#                 output = model(src, inp)\n",
    "#                 out_num = output.argmax(2)[-1].item()\n",
    "#                 pred.append(out_num)\n",
    "#             # print(\"predict: \", pred)\n",
    "#             np.savetxt('/home/mist/test/pred_'+str(i)+'.txt',pred) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88d7038b-acd0-4a0b-b1e3-19ecc355ce04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train loss: 8.884762128194174\n",
      "epoch: 0 val loss: 8.430649757385254\n",
      "epoch: 1 train loss: 8.3525284131368\n",
      "epoch: 1 val loss: 8.08516788482666\n",
      "epoch: 2 train loss: 8.023944775263468\n",
      "epoch: 2 val loss: 7.802675247192383\n",
      "epoch: 3 train loss: 7.7468611399332685\n",
      "epoch: 3 val loss: 7.55354118347168\n",
      "epoch: 4 train loss: 7.513567368189494\n",
      "epoch: 4 val loss: 7.368093967437744\n",
      "epoch: 5 train loss: 7.322382688522339\n",
      "epoch: 5 val loss: 7.217617988586426\n",
      "epoch: 6 train loss: 7.169830878575643\n",
      "epoch: 6 val loss: 7.065672874450684\n",
      "epoch: 7 train loss: 7.018868128458659\n",
      "epoch: 7 val loss: 6.933077335357666\n",
      "epoch: 8 train loss: 6.902270078659058\n",
      "epoch: 8 val loss: 6.776003837585449\n",
      "epoch: 9 train loss: 6.758063077926636\n",
      "epoch: 9 val loss: 6.628385066986084\n"
     ]
    }
   ],
   "source": [
    "# main_function\n",
    "\n",
    "# num_arrays,样本数？\n",
    "# hidden = d_model, 词向量维度\n",
    "# nlayers：encoder，decoder层数\n",
    "voc_size = 10000\n",
    "# num_arrays = 512\n",
    "# array_length = 50\n",
    "hidden = 64\n",
    "nlayers = 2\n",
    "model = TransformerModel(voc_size, voc_size, hidden=hidden, nlayers=nlayers)\n",
    "model = model.cuda()\n",
    "\n",
    "num_in = 100 #\n",
    "num_out = 10 #\n",
    "inp = indata_loader(num_in)\n",
    "tgt = outdata_loader(num_out)\n",
    "\n",
    "batch_size = 16 # 32\n",
    "epochs = 10 # 50\n",
    "dataset = AbundanceLoader(inp, tgt)\n",
    "#train_len = int(len(dataset) * 0.9)\n",
    "#val_len = len(dataset) - train_len\n",
    "#train_set, val_set = random_split(dataset, [train_len, val_len])\n",
    "# test_set\n",
    "test_len = int(len(dataset) * 0.1)\n",
    "model_len = len(dataset) - test_len\n",
    "model_set, test_set = random_split(dataset, [model_len, test_len])\n",
    "train_len = int(model_len * 0.9)\n",
    "val_len = model_len - train_len\n",
    "train_set, val_set = random_split(model_set, [train_len, val_len])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "# test_loader = DataLoader(test_set, batch_size=1, shuffle=True, num_workers=1)\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.5)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "best_loss = 100\n",
    "\n",
    "epoch_loss_all = []\n",
    "epoch_loss_val_all = []\n",
    "for i in range(epochs):\n",
    "    epoch_loss = train(model, criterion, optimizer, train_loader)\n",
    "    epoch_loss_val = validation(model, criterion, val_loader)\n",
    "    # scheduler.step()\n",
    "    epoch_loss_all.append(epoch_loss) # 保存\n",
    "    epoch_loss_val_all.append(epoch_loss_val) # 保存\n",
    "    print(\"epoch: {} train loss: {}\".format(i, epoch_loss))\n",
    "    print(\"epoch: {} val loss: {}\".format(i, epoch_loss_val))\n",
    "#     if epoch_loss_val < best_loss:\n",
    "#         best_loss = epoch_loss_val\n",
    "#         model_name = \"/home/mist/test/model_out/model_{0:.5f}.pt\".format(epoch_loss_val) #\n",
    "#         save(model.state_dict(), model_name)\n",
    "# # return model_name\n",
    "\n",
    "# model.load_state_dict(load(model_name))\n",
    "# # test(model, test_times=10)\n",
    "# test(model, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2571cd4-e994-49c9-ab99-b65fcbfb1087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(423),\n",
       " tensor(423),\n",
       " tensor(423),\n",
       " tensor(423),\n",
       " tensor(423),\n",
       " tensor(423),\n",
       " tensor(423),\n",
       " tensor(423),\n",
       " tensor(564),\n",
       " tensor(564),\n",
       " tensor(705),\n",
       " tensor(705),\n",
       " tensor(705),\n",
       " tensor(705),\n",
       " tensor(846),\n",
       " tensor(846),\n",
       " tensor(846),\n",
       " tensor(846),\n",
       " tensor(846),\n",
       " tensor(846),\n",
       " tensor(846),\n",
       " tensor(846),\n",
       " tensor(846),\n",
       " tensor(846),\n",
       " tensor(846),\n",
       " tensor(987),\n",
       " tensor(1128),\n",
       " tensor(1128),\n",
       " tensor(1128),\n",
       " tensor(1128),\n",
       " tensor(1270),\n",
       " tensor(1270),\n",
       " tensor(1270),\n",
       " tensor(1130),\n",
       " tensor(1272),\n",
       " tensor(1132),\n",
       " tensor(1132),\n",
       " tensor(1132),\n",
       " tensor(1132),\n",
       " tensor(1132),\n",
       " tensor(1133),\n",
       " tensor(1133),\n",
       " tensor(1133),\n",
       " tensor(1276),\n",
       " tensor(1419),\n",
       " tensor(1419),\n",
       " tensor(1419),\n",
       " tensor(1419),\n",
       " tensor(1419),\n",
       " tensor(1419),\n",
       " tensor(1562),\n",
       " tensor(1562),\n",
       " tensor(1705),\n",
       " tensor(1848),\n",
       " tensor(1848),\n",
       " tensor(1848),\n",
       " tensor(1848),\n",
       " tensor(1848),\n",
       " tensor(1708),\n",
       " tensor(1708),\n",
       " tensor(1567),\n",
       " tensor(1710),\n",
       " tensor(1710),\n",
       " tensor(1710),\n",
       " tensor(1569),\n",
       " tensor(1569),\n",
       " tensor(1569),\n",
       " tensor(1569),\n",
       " tensor(1569),\n",
       " tensor(1569),\n",
       " tensor(1569),\n",
       " tensor(1569),\n",
       " tensor(1569),\n",
       " tensor(1569),\n",
       " tensor(1569),\n",
       " tensor(1428),\n",
       " tensor(1287),\n",
       " tensor(1287),\n",
       " tensor(1287),\n",
       " tensor(1287),\n",
       " tensor(1288),\n",
       " tensor(1288),\n",
       " tensor(1288),\n",
       " tensor(1288),\n",
       " tensor(1290),\n",
       " tensor(1290),\n",
       " tensor(1433),\n",
       " tensor(1433),\n",
       " tensor(1576),\n",
       " tensor(1576),\n",
       " tensor(1577),\n",
       " tensor(1720),\n",
       " tensor(1720),\n",
       " tensor(1577),\n",
       " tensor(1434),\n",
       " tensor(1578),\n",
       " tensor(1721),\n",
       " tensor(1865),\n",
       " tensor(1865),\n",
       " tensor(2010),\n",
       " tensor(2010),\n",
       " tensor(2010),\n",
       " tensor(1867),\n",
       " tensor(1724),\n",
       " tensor(1724),\n",
       " tensor(1868),\n",
       " tensor(2012),\n",
       " tensor(2012),\n",
       " tensor(2156),\n",
       " tensor(2156),\n",
       " tensor(2300),\n",
       " tensor(2157),\n",
       " tensor(2157),\n",
       " tensor(2157),\n",
       " tensor(2157),\n",
       " tensor(2157),\n",
       " tensor(2301),\n",
       " tensor(2445),\n",
       " tensor(2589),\n",
       " tensor(2734),\n",
       " tensor(2878),\n",
       " tensor(2878),\n",
       " tensor(2878),\n",
       " tensor(2878),\n",
       " tensor(2878),\n",
       " tensor(2878),\n",
       " tensor(3022),\n",
       " tensor(3022),\n",
       " tensor(3166),\n",
       " tensor(3166),\n",
       " tensor(3167),\n",
       " tensor(3167),\n",
       " tensor(3167),\n",
       " tensor(3167),\n",
       " tensor(3024),\n",
       " tensor(3169),\n",
       " tensor(3172),\n",
       " tensor(3318),\n",
       " tensor(3175),\n",
       " tensor(3175),\n",
       " tensor(3032),\n",
       " tensor(3034),\n",
       " tensor(3034),\n",
       " tensor(3034),\n",
       " tensor(3034),\n",
       " tensor(2891),\n",
       " tensor(2747),\n",
       " tensor(2603),\n",
       " tensor(2749),\n",
       " tensor(2752),\n",
       " tensor(2756),\n",
       " tensor(2756),\n",
       " tensor(2756),\n",
       " tensor(2903),\n",
       " tensor(3051),\n",
       " tensor(2907),\n",
       " tensor(2763),\n",
       " tensor(2911),\n",
       " tensor(2915),\n",
       " tensor(2915),\n",
       " tensor(2920),\n",
       " tensor(3068),\n",
       " tensor(3068),\n",
       " tensor(3068),\n",
       " tensor(3217),\n",
       " tensor(3217),\n",
       " tensor(3222),\n",
       " tensor(3078),\n",
       " tensor(2933),\n",
       " tensor(2938),\n",
       " tensor(2943),\n",
       " tensor(2943),\n",
       " tensor(3092),\n",
       " tensor(3241),\n",
       " tensor(3389),\n",
       " tensor(3389),\n",
       " tensor(3245),\n",
       " tensor(3394),\n",
       " tensor(3250),\n",
       " tensor(3250),\n",
       " tensor(3254),\n",
       " tensor(3403),\n",
       " tensor(3403),\n",
       " tensor(3403),\n",
       " tensor(3552),\n",
       " tensor(3556),\n",
       " tensor(3558),\n",
       " tensor(3412),\n",
       " tensor(3412),\n",
       " tensor(3412),\n",
       " tensor(3412),\n",
       " tensor(3415),\n",
       " tensor(3415),\n",
       " tensor(3563),\n",
       " tensor(3712),\n",
       " tensor(3860),\n",
       " tensor(3860),\n",
       " tensor(3860),\n",
       " tensor(3862),\n",
       " tensor(3715),\n",
       " tensor(3568),\n",
       " tensor(3568),\n",
       " tensor(3568),\n",
       " tensor(3420),\n",
       " tensor(3421),\n",
       " tensor(3569),\n",
       " tensor(3716),\n",
       " tensor(3568),\n",
       " tensor(3567),\n",
       " tensor(3715),\n",
       " tensor(3566),\n",
       " tensor(3564),\n",
       " tensor(3711),\n",
       " tensor(3711),\n",
       " tensor(3562),\n",
       " tensor(3708),\n",
       " tensor(3706),\n",
       " tensor(3853),\n",
       " tensor(3853),\n",
       " tensor(3852),\n",
       " tensor(3702),\n",
       " tensor(3702),\n",
       " tensor(3701),\n",
       " tensor(3699),\n",
       " tensor(3698),\n",
       " tensor(3846),\n",
       " tensor(3992),\n",
       " tensor(3844),\n",
       " tensor(3844),\n",
       " tensor(3844),\n",
       " tensor(3695),\n",
       " tensor(3693),\n",
       " tensor(3840),\n",
       " tensor(3840),\n",
       " tensor(3837),\n",
       " tensor(3835),\n",
       " tensor(3686),\n",
       " tensor(3833),\n",
       " tensor(3979),\n",
       " tensor(4126),\n",
       " tensor(4272),\n",
       " tensor(4124),\n",
       " tensor(4271),\n",
       " tensor(4269),\n",
       " tensor(4121),\n",
       " tensor(3973),\n",
       " tensor(4119),\n",
       " tensor(4265),\n",
       " tensor(4117),\n",
       " tensor(4117),\n",
       " tensor(4264),\n",
       " tensor(4264),\n",
       " tensor(4264),\n",
       " tensor(4410),\n",
       " tensor(4262),\n",
       " tensor(4113),\n",
       " tensor(4112),\n",
       " tensor(4259),\n",
       " tensor(4112),\n",
       " tensor(3964),\n",
       " tensor(4112),\n",
       " tensor(4112),\n",
       " tensor(3966),\n",
       " tensor(3966),\n",
       " tensor(4113),\n",
       " tensor(3967),\n",
       " tensor(3967),\n",
       " tensor(3820),\n",
       " tensor(3820),\n",
       " tensor(3673),\n",
       " tensor(3820),\n",
       " tensor(3820),\n",
       " tensor(3820),\n",
       " tensor(3673),\n",
       " tensor(3674),\n",
       " tensor(3674),\n",
       " tensor(3676),\n",
       " tensor(3826),\n",
       " tensor(3977),\n",
       " tensor(4128),\n",
       " tensor(4279),\n",
       " tensor(4132),\n",
       " tensor(4136),\n",
       " tensor(4136),\n",
       " tensor(4141),\n",
       " tensor(4146),\n",
       " tensor(4297),\n",
       " tensor(4302),\n",
       " tensor(4306),\n",
       " tensor(4160),\n",
       " tensor(4014),\n",
       " tensor(4165),\n",
       " tensor(4169),\n",
       " tensor(4174),\n",
       " tensor(4325),\n",
       " tensor(4476),\n",
       " tensor(4330),\n",
       " tensor(4183),\n",
       " tensor(4334),\n",
       " tensor(4334),\n",
       " tensor(4337),\n",
       " tensor(4337),\n",
       " tensor(4337),\n",
       " tensor(4341),\n",
       " tensor(4491),\n",
       " tensor(4641),\n",
       " tensor(4495),\n",
       " tensor(4499),\n",
       " tensor(4499),\n",
       " tensor(4499),\n",
       " tensor(4502),\n",
       " tensor(4505),\n",
       " tensor(4655),\n",
       " tensor(4655),\n",
       " tensor(4657),\n",
       " tensor(4657),\n",
       " tensor(4510),\n",
       " tensor(4660),\n",
       " tensor(4810),\n",
       " tensor(4810),\n",
       " tensor(4813),\n",
       " tensor(4813),\n",
       " tensor(4665),\n",
       " tensor(4816),\n",
       " tensor(4820),\n",
       " tensor(4824),\n",
       " tensor(4827),\n",
       " tensor(4677),\n",
       " tensor(4679),\n",
       " tensor(4528),\n",
       " tensor(4377),\n",
       " tensor(4377),\n",
       " tensor(4378),\n",
       " tensor(4529),\n",
       " tensor(4529),\n",
       " tensor(4528),\n",
       " tensor(4528),\n",
       " tensor(4527),\n",
       " tensor(4376),\n",
       " tensor(4376),\n",
       " tensor(4526),\n",
       " tensor(4525),\n",
       " tensor(4525),\n",
       " tensor(4525),\n",
       " tensor(4374),\n",
       " tensor(4223),\n",
       " tensor(4223),\n",
       " tensor(4223),\n",
       " tensor(4223),\n",
       " tensor(4374),\n",
       " tensor(4374),\n",
       " tensor(4524),\n",
       " tensor(4524),\n",
       " tensor(4522),\n",
       " tensor(4520),\n",
       " tensor(4370),\n",
       " tensor(4518),\n",
       " tensor(4516),\n",
       " tensor(4664),\n",
       " tensor(4664),\n",
       " tensor(4661),\n",
       " tensor(4511),\n",
       " tensor(4361),\n",
       " tensor(4361),\n",
       " tensor(4359),\n",
       " tensor(4508),\n",
       " tensor(4657),\n",
       " tensor(4507),\n",
       " tensor(4506),\n",
       " tensor(4655),\n",
       " tensor(4655),\n",
       " tensor(4805),\n",
       " tensor(4805),\n",
       " tensor(4654),\n",
       " tensor(4652),\n",
       " tensor(4650),\n",
       " tensor(4649),\n",
       " tensor(4649),\n",
       " tensor(4647),\n",
       " tensor(4798),\n",
       " tensor(4948),\n",
       " tensor(5099),\n",
       " tensor(4947),\n",
       " tensor(4946),\n",
       " tensor(4795),\n",
       " tensor(4794),\n",
       " tensor(4644),\n",
       " tensor(4493),\n",
       " tensor(4493),\n",
       " tensor(4643),\n",
       " tensor(4492),\n",
       " tensor(4492),\n",
       " tensor(4341),\n",
       " tensor(4190),\n",
       " tensor(4190),\n",
       " tensor(4340),\n",
       " tensor(4340),\n",
       " tensor(4490),\n",
       " tensor(4339),\n",
       " tensor(4338),\n",
       " tensor(4336),\n",
       " tensor(4187),\n",
       " tensor(4335),\n",
       " tensor(4186),\n",
       " tensor(4186),\n",
       " tensor(4186),\n",
       " tensor(4187),\n",
       " tensor(4038),\n",
       " tensor(3890),\n",
       " tensor(3890),\n",
       " tensor(3742),\n",
       " tensor(3891),\n",
       " tensor(4040),\n",
       " tensor(4188),\n",
       " tensor(4040),\n",
       " tensor(3892),\n",
       " tensor(3742),\n",
       " tensor(3891),\n",
       " tensor(3890),\n",
       " tensor(3741),\n",
       " tensor(3739),\n",
       " tensor(3589),\n",
       " tensor(3589),\n",
       " tensor(3589),\n",
       " tensor(3439),\n",
       " tensor(3289),\n",
       " tensor(3287),\n",
       " tensor(3436),\n",
       " tensor(3435),\n",
       " tensor(3285),\n",
       " tensor(3134),\n",
       " tensor(3132),\n",
       " tensor(3281),\n",
       " tensor(3131),\n",
       " tensor(3280),\n",
       " tensor(3130),\n",
       " tensor(3130),\n",
       " tensor(3280),\n",
       " tensor(3280),\n",
       " tensor(3279),\n",
       " tensor(3428),\n",
       " tensor(3427),\n",
       " tensor(3575),\n",
       " tensor(3575),\n",
       " tensor(3723),\n",
       " tensor(3573),\n",
       " tensor(3721),\n",
       " tensor(3719),\n",
       " tensor(3719),\n",
       " tensor(3717),\n",
       " tensor(3717),\n",
       " tensor(3717),\n",
       " tensor(3717),\n",
       " tensor(3866),\n",
       " tensor(3866),\n",
       " tensor(4015),\n",
       " tensor(4015),\n",
       " tensor(4164),\n",
       " tensor(4313),\n",
       " tensor(4313),\n",
       " tensor(4313),\n",
       " tensor(4165),\n",
       " tensor(4016),\n",
       " tensor(3868),\n",
       " tensor(4017),\n",
       " tensor(4017),\n",
       " tensor(4017),\n",
       " tensor(3869),\n",
       " tensor(3721),\n",
       " tensor(3721),\n",
       " tensor(3722),\n",
       " tensor(3722),\n",
       " tensor(3872),\n",
       " tensor(4023),\n",
       " tensor(4174),\n",
       " tensor(4325),\n",
       " tensor(4176),\n",
       " tensor(4179),\n",
       " tensor(4030),\n",
       " tensor(4030),\n",
       " tensor(4030),\n",
       " tensor(3881),\n",
       " tensor(3883),\n",
       " tensor(3883),\n",
       " tensor(3886),\n",
       " tensor(4038),\n",
       " tensor(4190),\n",
       " tensor(4191),\n",
       " tensor(4191),\n",
       " tensor(4042),\n",
       " tensor(4044),\n",
       " tensor(3896),\n",
       " tensor(3748),\n",
       " tensor(3900),\n",
       " tensor(3903),\n",
       " tensor(3903),\n",
       " tensor(3755),\n",
       " tensor(3607),\n",
       " tensor(3607),\n",
       " tensor(3459),\n",
       " tensor(3311),\n",
       " tensor(3311),\n",
       " tensor(3163),\n",
       " tensor(3014),\n",
       " tensor(2866),\n",
       " tensor(2717),\n",
       " tensor(2569),\n",
       " tensor(2420),\n",
       " tensor(2270),\n",
       " tensor(2270),\n",
       " tensor(2270),\n",
       " tensor(2270),\n",
       " tensor(2270),\n",
       " tensor(2270),\n",
       " tensor(2120),\n",
       " tensor(2120),\n",
       " tensor(2120),\n",
       " tensor(2120),\n",
       " tensor(2120),\n",
       " tensor(2120),\n",
       " tensor(1970),\n",
       " tensor(1970),\n",
       " tensor(1820),\n",
       " tensor(1670),\n",
       " tensor(1519),\n",
       " tensor(1368),\n",
       " tensor(1368),\n",
       " tensor(1216),\n",
       " tensor(1216),\n",
       " tensor(1216),\n",
       " tensor(1216),\n",
       " tensor(1216),\n",
       " tensor(1064),\n",
       " tensor(1064),\n",
       " tensor(913),\n",
       " tensor(761),\n",
       " tensor(609),\n",
       " tensor(457),\n",
       " tensor(457),\n",
       " tensor(457),\n",
       " tensor(306),\n",
       " tensor(306),\n",
       " tensor(306),\n",
       " tensor(154),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(154),\n",
       " tensor(154),\n",
       " tensor(306),\n",
       " tensor(306),\n",
       " tensor(306),\n",
       " tensor(306),\n",
       " tensor(457),\n",
       " tensor(610),\n",
       " tensor(762),\n",
       " tensor(915),\n",
       " tensor(1067),\n",
       " tensor(1218),\n",
       " tensor(1370),\n",
       " tensor(1522),\n",
       " tensor(1522),\n",
       " tensor(1522),\n",
       " tensor(1674),\n",
       " tensor(1825),\n",
       " tensor(1825),\n",
       " tensor(1977),\n",
       " tensor(1977),\n",
       " tensor(2128),\n",
       " tensor(2128),\n",
       " tensor(2280),\n",
       " tensor(2280),\n",
       " tensor(2432),\n",
       " tensor(2584),\n",
       " tensor(2584),\n",
       " tensor(2736),\n",
       " tensor(2888),\n",
       " tensor(3041),\n",
       " tensor(3193),\n",
       " tensor(3345),\n",
       " tensor(3345),\n",
       " tensor(3498),\n",
       " tensor(3650),\n",
       " tensor(3803),\n",
       " tensor(3955),\n",
       " tensor(4107),\n",
       " tensor(4107),\n",
       " tensor(4259),\n",
       " tensor(4259),\n",
       " tensor(4259),\n",
       " tensor(4259),\n",
       " tensor(4259),\n",
       " tensor(4259),\n",
       " tensor(4411),\n",
       " tensor(4411),\n",
       " tensor(4411),\n",
       " tensor(4562),\n",
       " tensor(4411),\n",
       " tensor(4562),\n",
       " tensor(4562),\n",
       " tensor(4562),\n",
       " tensor(4712),\n",
       " tensor(4863),\n",
       " tensor(4861),\n",
       " tensor(4859),\n",
       " tensor(4856),\n",
       " tensor(4854),\n",
       " tensor(4853),\n",
       " tensor(4702),\n",
       " tensor(4701),\n",
       " tensor(4701),\n",
       " tensor(4853),\n",
       " tensor(5005),\n",
       " tensor(5005),\n",
       " tensor(5005),\n",
       " tensor(5157),\n",
       " tensor(5006),\n",
       " tensor(5006),\n",
       " tensor(5006),\n",
       " tensor(5158),\n",
       " tensor(5158),\n",
       " tensor(5158),\n",
       " tensor(5159),\n",
       " tensor(5159),\n",
       " tensor(5159),\n",
       " tensor(5159),\n",
       " tensor(5007),\n",
       " tensor(5007),\n",
       " tensor(4854),\n",
       " tensor(4854),\n",
       " tensor(5006),\n",
       " tensor(5005),\n",
       " tensor(4852),\n",
       " tensor(4851),\n",
       " tensor(4699),\n",
       " tensor(4547),\n",
       " tensor(4547),\n",
       " tensor(4547),\n",
       " tensor(4547),\n",
       " tensor(4699),\n",
       " tensor(4699),\n",
       " tensor(4699),\n",
       " tensor(4850),\n",
       " tensor(4699),\n",
       " tensor(4699),\n",
       " tensor(4699),\n",
       " tensor(4699),\n",
       " tensor(4851),\n",
       " tensor(4699),\n",
       " tensor(4701),\n",
       " tensor(4701),\n",
       " tensor(4702),\n",
       " tensor(4551),\n",
       " tensor(4552),\n",
       " tensor(4554),\n",
       " tensor(4404),\n",
       " tensor(4406),\n",
       " tensor(4407),\n",
       " tensor(4558),\n",
       " tensor(4558),\n",
       " tensor(4406),\n",
       " tensor(4405),\n",
       " tensor(4403),\n",
       " tensor(4251),\n",
       " tensor(4250),\n",
       " tensor(4099),\n",
       " tensor(4249),\n",
       " tensor(4400),\n",
       " tensor(4400),\n",
       " tensor(4400),\n",
       " tensor(4399),\n",
       " tensor(4550),\n",
       " tensor(4550),\n",
       " tensor(4397),\n",
       " tensor(4549),\n",
       " tensor(4549),\n",
       " tensor(4549),\n",
       " tensor(4396),\n",
       " tensor(4548),\n",
       " tensor(4396),\n",
       " tensor(4244),\n",
       " tensor(4245),\n",
       " tensor(4395),\n",
       " tensor(4393),\n",
       " tensor(4393),\n",
       " tensor(4543),\n",
       " tensor(4543),\n",
       " tensor(4540),\n",
       " tensor(4690),\n",
       " tensor(4538),\n",
       " tensor(4688),\n",
       " tensor(4688),\n",
       " tensor(4536),\n",
       " tensor(4685),\n",
       " tensor(4835),\n",
       " tensor(4835),\n",
       " tensor(4832),\n",
       " tensor(4831),\n",
       " tensor(4831),\n",
       " tensor(4829),\n",
       " tensor(4979),\n",
       " tensor(4978),\n",
       " tensor(5128),\n",
       " tensor(5130),\n",
       " tensor(4978),\n",
       " tensor(4978),\n",
       " tensor(4826),\n",
       " tensor(4674),\n",
       " tensor(4675),\n",
       " tensor(4524),\n",
       " tensor(4524),\n",
       " tensor(4526),\n",
       " tensor(4376),\n",
       " tensor(4528),\n",
       " tensor(4529),\n",
       " tensor(4681),\n",
       " tensor(4682),\n",
       " tensor(4531),\n",
       " tensor(4379),\n",
       " tensor(4380),\n",
       " tensor(4381),\n",
       " tensor(4382),\n",
       " tensor(4383),\n",
       " tensor(4535),\n",
       " tensor(4534),\n",
       " tensor(4382),\n",
       " tensor(4534),\n",
       " tensor(4534),\n",
       " tensor(4383),\n",
       " tensor(4534),\n",
       " tensor(4686),\n",
       " tensor(4534),\n",
       " tensor(4535),\n",
       " tensor(4385),\n",
       " tensor(4536),\n",
       " tensor(4387),\n",
       " tensor(4539),\n",
       " tensor(4542),\n",
       " tensor(4393),\n",
       " tensor(4545),\n",
       " tensor(4548),\n",
       " tensor(4701),\n",
       " tensor(4701),\n",
       " tensor(4704),\n",
       " tensor(4554),\n",
       " tensor(4707),\n",
       " tensor(4557),\n",
       " tensor(4559),\n",
       " tensor(4711),\n",
       " tensor(4713),\n",
       " tensor(4563),\n",
       " tensor(4412),\n",
       " tensor(4262),\n",
       " tensor(4109),\n",
       " tensor(4262),\n",
       " tensor(4415),\n",
       " tensor(4568),\n",
       " tensor(4568),\n",
       " tensor(4415),\n",
       " tensor(4568),\n",
       " tensor(4721),\n",
       " tensor(4568),\n",
       " tensor(4721),\n",
       " tensor(4722),\n",
       " tensor(4725),\n",
       " tensor(4574),\n",
       " tensor(4577),\n",
       " tensor(4577),\n",
       " tensor(4577),\n",
       " tensor(4580),\n",
       " tensor(4583),\n",
       " tensor(4431),\n",
       " tensor(4433),\n",
       " tensor(4435),\n",
       " tensor(4284),\n",
       " tensor(4284),\n",
       " tensor(4285),\n",
       " tensor(4285),\n",
       " tensor(4439),\n",
       " tensor(4438),\n",
       " tensor(4438),\n",
       " tensor(4589),\n",
       " tensor(4439),\n",
       " tensor(4591),\n",
       " tensor(4439),\n",
       " tensor(4592),\n",
       " tensor(4440),\n",
       " tensor(4287),\n",
       " tensor(4440),\n",
       " tensor(4288),\n",
       " tensor(4135),\n",
       " tensor(3982),\n",
       " tensor(4135),\n",
       " tensor(4137),\n",
       " tensor(4293),\n",
       " tensor(4140),\n",
       " tensor(4295),\n",
       " tensor(4143),\n",
       " tensor(4146),\n",
       " tensor(3994),\n",
       " tensor(4149),\n",
       " tensor(4304),\n",
       " tensor(4459),\n",
       " tensor(4614),\n",
       " tensor(4617),\n",
       " tensor(4620),\n",
       " tensor(4623),\n",
       " tensor(4623),\n",
       " tensor(4623),\n",
       " tensor(4625),\n",
       " tensor(4627),\n",
       " tensor(4782),\n",
       " tensor(4629),\n",
       " tensor(4476),\n",
       " tensor(4321),\n",
       " tensor(4321),\n",
       " tensor(4320),\n",
       " tensor(4475),\n",
       " tensor(4630),\n",
       " tensor(4475),\n",
       " tensor(4475),\n",
       " tensor(4631),\n",
       " tensor(4631),\n",
       " tensor(4477),\n",
       " tensor(4477),\n",
       " tensor(4632),\n",
       " tensor(4478),\n",
       " tensor(4633),\n",
       " tensor(4479),\n",
       " tensor(4328),\n",
       " tensor(4177),\n",
       " tensor(4180),\n",
       " tensor(4180),\n",
       " tensor(4028),\n",
       " tensor(4028),\n",
       " tensor(4031),\n",
       " tensor(4031),\n",
       " tensor(4031),\n",
       " tensor(4034),\n",
       " tensor(4187),\n",
       " tensor(4339),\n",
       " tensor(4492),\n",
       " tensor(4492),\n",
       " tensor(4491),\n",
       " tensor(4489),\n",
       " tensor(4643),\n",
       " tensor(4488),\n",
       " tensor(4641),\n",
       " tensor(4486),\n",
       " tensor(4486),\n",
       " tensor(4331),\n",
       " tensor(4176),\n",
       " tensor(4021),\n",
       " tensor(3866),\n",
       " tensor(3710),\n",
       " tensor(3554),\n",
       " tensor(3552),\n",
       " tensor(3705),\n",
       " tensor(3705),\n",
       " tensor(3703),\n",
       " tensor(3702),\n",
       " tensor(3700),\n",
       " tensor(3700),\n",
       " tensor(3700),\n",
       " tensor(3852),\n",
       " tensor(3852),\n",
       " tensor(3698),\n",
       " tensor(3543),\n",
       " tensor(3388),\n",
       " tensor(3388),\n",
       " tensor(3232),\n",
       " tensor(3077),\n",
       " tensor(2922),\n",
       " tensor(2922),\n",
       " ...]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test_set[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1745af2b-57a1-49a3-be17-6cc1f34c7543",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_set\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, test_set, max_len)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_len):\n\u001b[1;32m     47\u001b[0m     inp \u001b[38;5;241m=\u001b[39m LongTensor(pred)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m---> 48\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# predict = model.predictor(out[:, -1])\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     out_num \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m2\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36mTransformerModel.forward\u001b[0;34m(self, src, trg)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, src, trg):\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrg_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrg_mask\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(trg):\n\u001b[0;32m---> 59\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrg_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_square_subsequent_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     src_pad_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_len_mask(src)\n\u001b[1;32m     62\u001b[0m     trg_pad_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_len_mask(trg)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test(model, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ef8dca-8eaf-4957-a8cd-29600b22ab8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d9ec81a-ac9b-4469-b9b0-47a1a1e684a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerModel(10000, 10000, hidden=hidden, nlayers=nlayers)\n",
    "model.load_state_dict(load(model_name))\n",
    "test(model, val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac570989-2006-42f4-abcc-d763ba099994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c4ae0d5-9423-40f0-95e6-6c8a2b2c3126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.load_state_dict of TransformerModel(\n",
      "  (encoder): Embedding(10000, 64)\n",
      "  (pos_encoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (decoder): Embedding(10000, 64)\n",
      "  (pos_decoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (transformer): Transformer(\n",
      "    (encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (fc_out): Linear(in_features=64, out_features=10000, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(model.load_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d0480e-34e7-47e2-a3de-4fa9088fffbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
