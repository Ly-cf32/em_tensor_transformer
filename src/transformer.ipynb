{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff78b9c2-ced8-4a8d-9361-4f3b22f1aa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import argparse\n",
    "from numpy import arange, random\n",
    "from torch import save, load, no_grad, LongTensor\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8633a0c0-16f8-4de4-9250-5343bc887fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indata_loader(num_file):\n",
    "    data_array = []\n",
    "    for i in range(num_file):\n",
    "        file_name = '/home/mist/pc/wig_fin/pc_fin_' + str(i+1) + '.npy'\n",
    "        array = np.load(file_name)\n",
    "        for i in range(num_file):\n",
    "            data_array.append(array)\n",
    "    return data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a36c0b9c-3f94-4607-9bb2-a7e7f2d5f5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outdata_loader(num_file):\n",
    "    data_array = []\n",
    "    for i in range(num_file):\n",
    "        file_name = '/home/mist/mix/mix_np_out/m_' + str(i+1) + '_a_xa.temt'\n",
    "        array = np.loadtxt(file_name, skiprows=1, usecols = 1)\n",
    "        data_array.append(array)\n",
    "    return data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4aad6cc9-1c83-41fe-a8c3-b4079c59140b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# abundanceloader\n",
    "import numpy as np\n",
    "from torch import LongTensor\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# sequence_length = 1999-1 # ighm\n",
    "class AbundanceLoader(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        if len(x) != len(y):\n",
    "            raise ValueError(\"len(x) != len(y)\")\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return LongTensor(self.x[index]), LongTensor([0] + self.y[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed3c8517-136c-4c33-bd24-950c071c6533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "import torch\n",
    "from torch import nn\n",
    "import math\n",
    "\n",
    "# positional encoding\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, dropout=0.1, max_len=1998):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1) #\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "# transformer model\n",
    "class TransformerModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, intoken, outtoken, hidden, nlayers=3, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        nhead = hidden // 64\n",
    "\n",
    "        self.encoder = nn.Embedding(intoken, hidden) # nn.Embedding:词典大小，词向量维度\n",
    "        self.pos_encoder = PositionalEncoding(hidden, dropout)\n",
    "\n",
    "        self.decoder = nn.Embedding(outtoken, hidden)\n",
    "        self.pos_decoder = PositionalEncoding(hidden, dropout)\n",
    "\n",
    "        self.inscale = math.sqrt(intoken)\n",
    "        self.outscale = math.sqrt(outtoken)\n",
    "\n",
    "        self.transformer = nn.Transformer(d_model=hidden, nhead=nhead, num_encoder_layers=nlayers,\n",
    "                                          num_decoder_layers=nlayers, dim_feedforward=hidden, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(hidden, outtoken)\n",
    "\n",
    "        self.src_mask = None\n",
    "        self.trg_mask = None\n",
    "        self.memory_mask = None\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = torch.triu(torch.ones(sz, sz), 1)\n",
    "        mask = mask.masked_fill(mask == 1, float('-inf'))\n",
    "        return mask\n",
    "\n",
    "    def make_len_mask(self, inp):\n",
    "        return (inp == 0).transpose(0, 1)\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        if self.trg_mask is None or self.trg_mask.size(0) != len(trg):\n",
    "            self.trg_mask = self.generate_square_subsequent_mask(len(trg)).to(trg.device)\n",
    "\n",
    "        src_pad_mask = self.make_len_mask(src)\n",
    "        trg_pad_mask = self.make_len_mask(trg)\n",
    "\n",
    "        src = self.encoder(src)\n",
    "        src = self.pos_encoder(src)\n",
    "\n",
    "        trg = self.decoder(trg)\n",
    "        trg = self.pos_decoder(trg)\n",
    "        output = self.transformer(src, trg, tgt_mask=self.trg_mask)\n",
    "        # output = self.transformer(src, trg, src_mask=self.src_mask, tgt_mask=self.trg_mask,\n",
    "        #                           memory_mask=self.memory_mask,\n",
    "        #                           src_key_padding_mask=src_pad_mask, tgt_key_padding_mask=trg_pad_mask,\n",
    "        #                           memory_key_padding_mask=src_pad_mask)\n",
    "        output = self.fc_out(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "100ae2cc-c4a9-4dbb-8650-a70c15fceb12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 训练过程\n",
    "def train(model, criterion, optimizer, loader):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(loader):\n",
    "        src, tgt = batch\n",
    "        src, tgt = src.transpose(1, 0).cuda(), tgt.transpose(1, 0).cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, tgt[:-1, :])\n",
    "        n = output.shape[-1]\n",
    "        loss = criterion(output.reshape(-1, n), tgt[1:, :].reshape(-1))\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(loader)\n",
    "\n",
    "\n",
    "# 验证\n",
    "def validation(model, criterion, loader):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with no_grad():\n",
    "        for i, batch in enumerate(loader):\n",
    "            src, tgt = batch\n",
    "            src, tgt = src.transpose(1, 0).cuda(), tgt.transpose(1, 0).cuda()\n",
    "            output = model(src, tgt[:-1, :])\n",
    "            n = output.shape[-1]\n",
    "            loss = criterion(output.reshape(-1, n), tgt[1:, :].reshape(-1))\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(loader)\n",
    "\n",
    "\n",
    "# 测试\n",
    "def test(model, max_len=3, test_times=1):\n",
    "    model = model.cuda()\n",
    "    model.eval()\n",
    "    with no_grad():\n",
    "        for i in range(test_times):\n",
    "            s = random.randint(1, 4998)\n",
    "            cpu_src = [(s + j) * 2 for j in range(max_len)]\n",
    "            src = LongTensor(cpu_src).unsqueeze(1).cuda()\n",
    "            tgt = [0] + [(s + j) * 2 + 1 for j in range(max_len)]\n",
    "            pred = [0]\n",
    "            for j in range(max_len):\n",
    "                inp = LongTensor(pred).unsqueeze(1).cuda()\n",
    "                output = model(src, inp)\n",
    "                out_num = output.argmax(2)[-1].item()\n",
    "                pred.append(out_num)\n",
    "            print(\"input: \", cpu_src)\n",
    "            print(\"target: \", tgt)\n",
    "            print(\"predict: \", pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b02450d-99d7-4478-a817-182ee9ae6a58",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train loss: 5.850770480196241\n",
      "epoch: 0 val loss: 4.179392635822296\n",
      "epoch: 1 train loss: 3.520250696531484\n",
      "epoch: 1 val loss: 2.7418691515922546\n",
      "epoch: 2 train loss: 2.470017470104594\n",
      "epoch: 2 val loss: 2.0271848887205124\n",
      "epoch: 3 train loss: 1.9716892981193435\n",
      "epoch: 3 val loss: 1.726217582821846\n",
      "epoch: 4 train loss: 1.7476668811180223\n",
      "epoch: 4 val loss: 1.5853588283061981\n",
      "epoch: 5 train loss: 1.6326723770356515\n",
      "epoch: 5 val loss: 1.5048100799322128\n",
      "epoch: 6 train loss: 1.563377662443779\n",
      "epoch: 6 val loss: 1.4525576084852219\n",
      "epoch: 7 train loss: 1.5152420796139139\n",
      "epoch: 7 val loss: 1.410763919353485\n",
      "epoch: 8 train loss: 1.477576606710192\n",
      "epoch: 8 val loss: 1.3761582970619202\n",
      "epoch: 9 train loss: 1.4467167484928185\n",
      "epoch: 9 val loss: 1.3474269956350327\n",
      "epoch: 10 train loss: 1.4212190215016756\n",
      "epoch: 10 val loss: 1.3210552632808685\n",
      "epoch: 11 train loss: 1.397960577212589\n",
      "epoch: 11 val loss: 1.2989573031663895\n",
      "epoch: 12 train loss: 1.3776290718938264\n",
      "epoch: 12 val loss: 1.2789745479822159\n",
      "epoch: 13 train loss: 1.3597226226833505\n",
      "epoch: 13 val loss: 1.2592517584562302\n",
      "epoch: 14 train loss: 1.3429940082657505\n",
      "epoch: 14 val loss: 1.2412266284227371\n",
      "epoch: 15 train loss: 1.3276545766373755\n",
      "epoch: 15 val loss: 1.2238413244485855\n",
      "epoch: 16 train loss: 1.3132548600855007\n",
      "epoch: 16 val loss: 1.2092587053775787\n",
      "epoch: 17 train loss: 1.299637153115071\n",
      "epoch: 17 val loss: 1.1933961808681488\n",
      "epoch: 18 train loss: 1.286929639292435\n",
      "epoch: 18 val loss: 1.1794558316469193\n",
      "epoch: 19 train loss: 1.2759141838046866\n",
      "epoch: 19 val loss: 1.1679508686065674\n",
      "epoch: 20 train loss: 1.262869096138108\n",
      "epoch: 20 val loss: 1.1535015553236008\n",
      "epoch: 21 train loss: 1.2524143020871659\n",
      "epoch: 21 val loss: 1.1410188376903534\n",
      "epoch: 22 train loss: 1.2414472992991057\n",
      "epoch: 22 val loss: 1.1281906068325043\n",
      "epoch: 23 train loss: 1.231097401027948\n",
      "epoch: 23 val loss: 1.1172442734241486\n",
      "epoch: 24 train loss: 1.2211605528710594\n",
      "epoch: 24 val loss: 1.106121227145195\n",
      "epoch: 25 train loss: 1.2118147007176574\n",
      "epoch: 25 val loss: 1.093482419848442\n",
      "epoch: 26 train loss: 1.2030113095968542\n",
      "epoch: 26 val loss: 1.084469050168991\n",
      "epoch: 27 train loss: 1.1948180433730005\n",
      "epoch: 27 val loss: 1.0750931948423386\n",
      "epoch: 28 train loss: 1.1856314850525118\n",
      "epoch: 28 val loss: 1.065684586763382\n",
      "epoch: 29 train loss: 1.1773811981711588\n",
      "epoch: 29 val loss: 1.0556222051382065\n",
      "epoch: 30 train loss: 1.1694982286909936\n",
      "epoch: 30 val loss: 1.046087995171547\n",
      "epoch: 31 train loss: 1.1617141324029843\n",
      "epoch: 31 val loss: 1.0385134518146515\n",
      "epoch: 32 train loss: 1.153725352085812\n",
      "epoch: 32 val loss: 1.0296475291252136\n",
      "epoch: 33 train loss: 1.1469864425524858\n",
      "epoch: 33 val loss: 1.0220482274889946\n",
      "epoch: 34 train loss: 1.1403976729218388\n",
      "epoch: 34 val loss: 1.0121767595410347\n",
      "epoch: 35 train loss: 1.1326923068140593\n",
      "epoch: 35 val loss: 1.004840299487114\n",
      "epoch: 36 train loss: 1.1263919850470314\n",
      "epoch: 36 val loss: 0.9968534559011459\n",
      "epoch: 37 train loss: 1.1198130560592867\n",
      "epoch: 37 val loss: 0.9914000928401947\n",
      "epoch: 38 train loss: 1.1144783966977831\n",
      "epoch: 38 val loss: 0.983755998313427\n",
      "epoch: 39 train loss: 1.106998839848478\n",
      "epoch: 39 val loss: 0.9752533510327339\n",
      "epoch: 40 train loss: 1.1009138856135623\n",
      "epoch: 40 val loss: 0.9686824530363083\n",
      "epoch: 41 train loss: 1.0965655588767897\n",
      "epoch: 41 val loss: 0.962759867310524\n",
      "epoch: 42 train loss: 1.090613475987609\n",
      "epoch: 42 val loss: 0.9578098058700562\n",
      "epoch: 43 train loss: 1.0849315868297094\n",
      "epoch: 43 val loss: 0.9516435191035271\n",
      "epoch: 44 train loss: 1.079398509482263\n",
      "epoch: 44 val loss: 0.9444637447595596\n",
      "epoch: 45 train loss: 1.0741827958066699\n",
      "epoch: 45 val loss: 0.9396096393465996\n",
      "epoch: 46 train loss: 1.0688993779706284\n",
      "epoch: 46 val loss: 0.9330692887306213\n",
      "epoch: 47 train loss: 1.064024698566383\n",
      "epoch: 47 val loss: 0.9275855273008347\n",
      "epoch: 48 train loss: 1.0594884257921031\n",
      "epoch: 48 val loss: 0.9223230481147766\n",
      "epoch: 49 train loss: 1.0544750539349839\n",
      "epoch: 49 val loss: 0.917551264166832\n"
     ]
    }
   ],
   "source": [
    "# main_function\n",
    "\n",
    "# num_arrays,样本数？\n",
    "# hidden = d_model, 词向量维度\n",
    "# nlayers：encoder，decoder层数\n",
    "voc_size = 10000\n",
    "# num_arrays = 512\n",
    "# array_length = 50\n",
    "hidden = 64\n",
    "nlayers = 2\n",
    "model = TransformerModel(voc_size, voc_size, hidden=hidden, nlayers=nlayers)\n",
    "model = model.cuda()\n",
    "\n",
    "num_in = 50\n",
    "num_out = 2500\n",
    "inp = indata_loader(num_in)\n",
    "tgt = outdata_loader(num_out)\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "dataset = AbundanceLoader(inp, tgt)\n",
    "train_len = int(len(dataset) * 0.9)\n",
    "val_len = len(dataset) - train_len\n",
    "train_set, val_set = random_split(dataset, [train_len, val_len])\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.5)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "best_loss = 100\n",
    "\n",
    "for i in range(epochs):\n",
    "    epoch_loss = train(model, criterion, optimizer, train_loader)\n",
    "    epoch_loss_val = validation(model, criterion, val_loader)\n",
    "    # scheduler.step()\n",
    "    print(\"epoch: {} train loss: {}\".format(i, epoch_loss))\n",
    "    print(\"epoch: {} val loss: {}\".format(i, epoch_loss_val))\n",
    "    if epoch_loss_val < best_loss:\n",
    "        best_loss = epoch_loss_val\n",
    "        model_name = \"/home/mist/mix/model_out/model_{0:.5f}.pt\".format(epoch_loss_val) #\n",
    "        save(model.state_dict(), model_name)\n",
    "# return model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "85e348b4-0023-4208-a1bb-955c221cd61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f6e47280-a1b3-44b7-a477-4cb879adcefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 2            |        cudaMalloc retries: 2         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |   23135 MB |   23135 MB |   32204 MB |    9068 MB |\n",
      "|       from large pool |   23114 MB |   23114 MB |   32175 MB |    9061 MB |\n",
      "|       from small pool |      21 MB |      21 MB |      28 MB |       7 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |   23135 MB |   23135 MB |   32204 MB |    9068 MB |\n",
      "|       from large pool |   23114 MB |   23114 MB |   32175 MB |    9061 MB |\n",
      "|       from small pool |      21 MB |      21 MB |      28 MB |       7 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |   23182 MB |   23182 MB |   23182 MB |       0 B  |\n",
      "|       from large pool |   23160 MB |   23160 MB |   23160 MB |       0 B  |\n",
      "|       from small pool |      22 MB |      22 MB |      22 MB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |   47740 KB |     843 MB |    4519 MB |    4473 MB |\n",
      "|       from large pool |   46971 KB |     841 MB |    4496 MB |    4450 MB |\n",
      "|       from small pool |     768 KB |       5 MB |      23 MB |      22 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     318    |     336    |     546    |     228    |\n",
      "|       from large pool |     143    |     143    |     226    |      83    |\n",
      "|       from small pool |     175    |     233    |     320    |     145    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     318    |     336    |     546    |     228    |\n",
      "|       from large pool |     143    |     143    |     226    |      83    |\n",
      "|       from small pool |     175    |     233    |     320    |     145    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      54    |      54    |      54    |       0    |\n",
      "|       from large pool |      43    |      43    |      43    |       0    |\n",
      "|       from small pool |      11    |      11    |      11    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      22    |      30    |     105    |      83    |\n",
      "|       from large pool |      16    |      16    |      74    |      58    |\n",
      "|       from small pool |       6    |      14    |      31    |      25    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71361b6d-d818-440d-91e1-f011cb794729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_generate\n",
    "import random\n",
    "\n",
    "def generate_random_arrays(num_arrays, array_length):\n",
    "    random_arrays = []\n",
    "    for _ in range(num_arrays):\n",
    "        array = [random.randint(0, 100) for _ in range(array_length)]  # Change the range (0, 100) to your desired range\n",
    "        random_arrays.append(array)\n",
    "    return random_arrays"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
